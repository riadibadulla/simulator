# -*- coding: utf-8 -*-
"""Measuring FatNet.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1YxuoSUp1ts_tKMBwme-PqQK4j-mgJTew
"""

from torch.nn.modules.pooling import AdaptiveAvgPool2d
import torch.nn as nn
import torch.nn.functional as F
import torch
import torch.optim as optim
import pandas as pd
import numpy as np

device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')

def conv_block(in_channels, out_channels, k=3 ,pool_size=0):
  layers = [nn.Conv2d(in_channels, out_channels, kernel_size=k, padding="same"),
            nn.BatchNorm2d(out_channels),
            nn.ReLU(inplace=True)]
  if pool_size !=0:
    layers.append(nn.AdaptiveAvgPool2d(pool_size))
  return nn.Sequential(*layers)

"""# FATNET"""

class FatNet(nn.Module):
    def __init__(self):
        super().__init__()
        self.conv1 = conv_block(3,64,k=7,pool_size=16)
        self.res1 = nn.Sequential(conv_block(64,64), conv_block(64,64))
        self.res2 = nn.Sequential(conv_block(64,64,), conv_block(64,64))

        self.conv2 = nn.Sequential(conv_block(64,82,k=4,pool_size=10), conv_block(82,82,k=5))
        self.res3 = nn.Sequential(conv_block(82,82,k=5), conv_block(82,82,k=5))

        self.conv3 = nn.Sequential(conv_block(82,78,k=7), conv_block(78,78,k=10))
        self.res4 = nn.Sequential(conv_block(78,78,k=10), conv_block(78,78,k=10))

        self.conv4 = nn.Sequential(conv_block(78,151,k=10), conv_block(151,155,k=10))
        self.res5 = nn.Sequential(conv_block(155,151,k=10), conv_block(151,155,k=10))
        self.classifier = nn.Sequential(
                                        nn.Dropout(p=0.2, inplace=False),
                                        nn.Conv2d(155, 1, kernel_size=10, padding="same"),
                                        nn.Flatten())

    def forward(self, x):
        x = self.conv1(x)
        x = self.res1(x)+x
        x = self.res2(x)+x
        x = self.conv2(x)
        x = self.res3(x)+x
        x = self.conv3(x)
        x = self.res4(x)+x
        x = self.conv4(x)
        x = self.res5(x)+x
        x = self.classifier(x)
        return x

"""resnet"""

class Net(nn.Module):
    def __init__(self):
        super().__init__()
        self.conv1 = conv_block(3,64,k=7,pool_size=16)
        self.res1 = nn.Sequential(conv_block(64,64), conv_block(64,64))
        self.res2 = nn.Sequential(conv_block(64,64), conv_block(64,64))

        self.conv2 = nn.Sequential(conv_block(64,128,pool_size=8), conv_block(128,128))
        self.res3 = nn.Sequential(conv_block(128,128), conv_block(128,128))

        self.conv3 = nn.Sequential(conv_block(128,256,pool_size=4), conv_block(256,256))
        self.res4 = nn.Sequential(conv_block(256,256), conv_block(256,256))

        self.conv4 = nn.Sequential(conv_block(256,512,pool_size=2), conv_block(512,512))
        self.res5 = nn.Sequential(conv_block(512,512), conv_block(512,512))
        self.pool = nn.MaxPool2d(2)
        self.classifier = nn.Sequential(nn.Flatten(),
                                        nn.Dropout(p=0.2, inplace=False),
                                        nn.Linear(512, 100))

    def forward(self, x):
        x = self.conv1(x)
        x = self.res1(x)+x
        x = self.res2(x)+x
        x = self.conv2(x)
        x = self.res3(x)+x
        x = self.conv3(x)
        x = self.res4(x)+x
        x = self.conv4(x)
        x = self.res5(x)+x
        x = self.pool(x)
        x = self.classifier(x)
        return x

"""Measure"""

net = Net()
net.to(device)

dummy_input = torch.randn(64, 3,32,32, dtype=torch.float).to(device)

starter, ender = torch.cuda.Event(enable_timing=True), torch.cuda.Event(enable_timing=True)
repetitions = 300
timings=np.zeros((repetitions,1))
#GPU-WARM-UP
for _ in range(10):
    _ = net(dummy_input)
# MEASURE PERFORMANCE
with torch.no_grad():
    for rep in range(repetitions):
        starter.record()
        _ = net(dummy_input)
        ender.record()
        # WAIT FOR GPU SYNC
        torch.cuda.synchronize()
        curr_time = starter.elapsed_time(ender)
        timings[rep] = curr_time
mean_syn = np.sum(timings) / repetitions
std_syn = np.std(timings)
print(mean_syn)